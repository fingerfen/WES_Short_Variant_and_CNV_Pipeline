configfile : "config.yaml"

#Nhat Duong
#August 20th 2019
#WES pipeline for going from variant file


#Specify the final file that we desire to get, which is the homepage.html file
ALL_WEB = expand("data/endpoints/{sample}_homepage.html", sample=config["samples"])


# First rule in the Snakefile. This will get executed and call for the WEBPAGE to be created. 
# Any rules that are required to be executed to produce the WEBPAGE will be executed. 
rule all:
	input:
		ALL_WEB


## First rule in the pipeline. Decompose the VCF file to standardize the format of it
rule decomp:
	input:
		str(config["vcf_path"]) + "{sample}" + str(config["vcf_ext"]),
	output:
		"data/interim/{sample}.vcfdecom.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		"vt decompose {input} -o {output}"
		

## Normalize to standardize the format of the VCF file
rule normalizem:
	input:
		decomp = "data/interim/{sample}.vcfdecom.vcf",
		fa=lambda wildcards: config["references"]
	output:
		"data/interim/{sample}.vcf.decom_norm.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		"vt normalize {input.decomp} -o {output} -r {input.fa}"
		

## Adding annotation to each of the VCF calls (aka, commenting each entry/row of the VCf file)
rule annotation1:
	input:
		lua = lambda wildcards: config["lua"],
		tempanno = str(config["temppath"]) + "temp.anno",
		norm = "data/interim/{sample}.vcf.decom_norm.vcf"
	output:
		"data/interim/{sample}.vcf.anno.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		"vcfanno -p 12 -lua {input.lua} {input.tempanno} {input.norm} > {output}"

## More annotation
rule annotation2:
	input:
		temp2anno = str(config["temppath"]) + "temp2.anno",
		anno1 = "data/interim/{sample}.vcf.anno.vcf"
	output:
		"data/interim/{sample}.vcf.anno2.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		"vcfanno -p 12 {input.temp2anno} {input.anno1} > {output}"

## More annotation
rule annotation3:
	input:
		temp3anno = str(config["temppath"]) + "temp3.anno",
		anno2 = "data/interim/{sample}.vcf.anno2.vcf"
	output:
		"data/interim/{sample}.vcf.anno3.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		"vcfanno -p 12 {input.temp3anno} {input.anno2} > {output}"


# Add snp EFFECTS into the vcf file - annotation
rule snpeff:
	input:
		anno3 = "data/interim/{sample}.vcf.anno3.vcf"
	output:
		"data/interim/{sample}.vcf.anno.g.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		"java -Xmx2g -jar /opt/anaconda3/envs/snakemake/share/snpeff-4.3.1t-3/snpEff.jar -v hg19kg {input.anno3} > {output}"

#Classifying the results into different categories. No information are chagned here. Only transformed. 
rule filter_results:
	input:
		gvcf = "data/interim/{sample}.vcf.anno.g.vcf",
		script = str(config["scripts"]) + "filter_combined_GATK.py"
	output:
		gatk_DP_AD = "data/interim/gatk_filtered_DP_AD_{sample}.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		"python3 {input.script} {input.gvcf} > {output.gatk_DP_AD}"


## Uses GATK to separate the SNPS and INDELS
rule getSNPs:
	input:
		gatk_DP_AD = "data/interim/gatk_filtered_DP_AD_{sample}.vcf",
		fa=lambda wildcards: config["references"],
	output:
		snp_out = "data/interim/gatk_filtered_DP_AD_{sample}_raw_snps.vcf",
		indel_out = "data/interim/gatk_filtered_DP_AD_{sample}_raw_indels.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		"gatk SelectVariants -R {input.fa} -V {input.gatk_DP_AD} -select-type SNP -O {output.snp_out} &&"
		"gatk SelectVariants -R {input.fa} -V {input.gatk_DP_AD} -select-type INDEL -O {output.indel_out}"


## Filter out the SNPs and Indels according to the gatk conventions
## the code below are NOT commented out, don't delete
rule filterSNPs:
	input:
		raw_snps = "data/interim/gatk_filtered_DP_AD_{sample}_raw_snps.vcf",
		raw_indels = "data/interim/gatk_filtered_DP_AD_{sample}_raw_indels.vcf",
		fa=lambda wildcards: config["references"]
	output:
		filtered_snps = "data/interim/gatk_filtered_DP_AD_{sample}_PASS_annotated_snps.vcf",
		filtered_indels = "data/interim/gatk_filtered_DP_AD_{sample}_PASS_annotated_indels.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		"""gatk VariantFiltration -R {input.fa} -V {input.raw_snps} -O {output.filtered_snps} """
		"""--filter-expression "QD < 2.0" --filter-name "QD_less_than_2" """
		"""--filter-expression "FS > 60.0" --filter-name "FS_larger_than_60" """
		"""--filter-expression "MQ < 40.0" --filter-name "MQ_less_than_40" """
		"""--filter-expression "MQRankSum < -12.5" --filter-name "MQranksum_less_than_-12.5" """
		"""--filter-expression "ReadPosRankSum < -8.0" --filter-name "readposranksum_less_than_-8" && """
		"""gatk VariantFiltration -R {input.fa} -V {input.raw_indels} -O {output.filtered_indels} """
		"""--filter-expression "QD < 2.0" --filter-name "QD_less_than_2" """
		"""--filter-expression "FS > 200.0" --filter-name "FS_larger_than_200" """
		"""--filter-expression "ReadPosRankSum < -20.0" --filter-name "readposranksum_less_than_-20" """


## Take in the SNPS and indels. Select for the ones what have PASS scores and those annotated with HIGH or MODERATE impacts. 
rule gen_PASS_high_moderate:
	input:
		filtered_snps = "data/interim/gatk_filtered_DP_AD_{sample}_PASS_annotated_snps.vcf",
		filtered_indels = "data/interim/gatk_filtered_DP_AD_{sample}_PASS_annotated_indels.vcf"
	output:
		pass_high_moderate = "data/interim/gatk_filtered_DP_AD_{sample}_PASS_high_moderate.vcf"
	threads: 1
	params:
		mem=r"4G"
	shell:
		'''awk '$7~/PASS/||/^#CHROM/' {input.filtered_snps} | grep 'HIGH\|MODERATE\|^#CHROM' > {output.pass_high_moderate} && '''
		'''awk '$7~/PASS/' {input.filtered_indels} | grep 'HIGH\|MODERATE' >> {output.pass_high_moderate}'''



## Read and process the SNP data. 
## Find gene associated with SNP entries and filter out any samples with >1000 called SNPs
## Put the final SNPs data w their associated GENEs in a database for easy access later on
rule gene_WES_mutation_matrix:
	input:
		script = str(config["scripts"]) + "1000_filter_mutation_matrix.py",
		gene_list = str(config["chromosome_file_path"]) + "hg19_genes.bed",
		pass_high_moderate = "data/interim/gatk_filtered_DP_AD_{sample}_PASS_high_moderate.vcf",
		#pass_high_moderate = "data/interim/gatk_filtered_DP_AD_{sample}_high_moderate.vcf"
	output:
		WES_mat = "data/interim/{sample}_WES_mutation_matrix.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --input {input.pass_high_moderate} --genelist {input.gene_list} --database {params.database} > {output.WES_mat}"


## Taking in the VCF matrix that was put into the Database and comparing gene vs gene between the two cohort. 
## Asking, is there a diff in THIS ONE SPECIFIC GENE in the Controls vs Cases cohort. 
rule gene2gene_analysis:
	input:
		script = str(config["scripts"]) + "stat_test_LOF_gene_pval.py",
		gene_list = str(config["chromosome_file_path"]) + "hg19_genes.bed",
		WES_mat = "data/interim/{sample}_WES_mutation_matrix.txt"
	output:
		gene2gene = "data/interim/{sample}_gene2gene_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} > {output.gene2gene}"

## This is the rule to compare GO term vs GO term. Comparing mutation in a certain GO term between the Controls vs Cases cohorts
rule GO_term_analysis:
	input:
		script = str(config["scripts"]) + "stat_test_LOF_GO_term_pval.py",
		gene_list = str(config["chromosome_file_path"]) + "hg19_genes.bed",
		go_terms = str(config["chromosome_file_path"]) + "human_GO.txt",
		go_functions = str(config["chromosome_file_path"]) + "go_def.txt",
		WES_mat = "data/interim/{sample}_WES_mutation_matrix.txt"
	output:
		go_res = "data/interim/{sample}_GO_term_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} --goterms {input.go_terms} --gofunctions {input.go_functions} > {output.go_res}"

## This is the rule to compare MP term vs MP term. Comparing mutation in a certain MP term between the Controls vs Cases cohorts
rule MP_term_analysis:
	input:
		script = str(config["scripts"]) + "stat_test_LOF_MP_term_pval.py",
		gene_list = str(config["chromosome_file_path"]) + "hg19_genes.bed",
		mp_terms = str(config["chromosome_file_path"]) + "human_MP_ws.txt",
		mp_functions = str(config["chromosome_file_path"]) + "mp_def.txt",
		WES_mat = "data/interim/{sample}_WES_mutation_matrix.txt"
	output:
		mp_res = "data/interim/{sample}_MP_term_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} --mpterms {input.mp_terms} --mpfunctions {input.mp_functions} > {output.mp_res}"


## Given that the BED file is already in the database, this takes the BED file from the database to perfrom gene vs gene analysis
rule affy_gene2gene_analysis:
	input:
		script = str(config["scripts"]) + "stat_test_LOF_Affy_gene_pval.py",
		gene_list = str(config["chromosome_file_path"]) + "hg19_genes.bed",
		bed = lambda wildcards: config["bed_file"],
		#WES_mat = "data/interim/{sample}_WES_mutation_matrix.txt"
	output:
		gene2gene = "data/interim/{sample}_Affy_gene2gene_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} > {output.gene2gene}"


## Performs GO term vs GO term analysis between the Controls vs Cases cohorts
rule affy_GO_term_analysis:
	input:
		script = str(config["scripts"]) + "stat_test_LOF_Affy_GO_term_pval.py",
		gene_list = str(config["chromosome_file_path"]) + "hg19_genes.bed",
		go_terms = str(config["chromosome_file_path"]) + "human_GO.txt",
		go_functions = str(config["chromosome_file_path"]) + "go_def.txt",
		bed = lambda wildcards: config["bed_file"],
		#WES_mat = "data/interim/{sample}_WES_mutation_matrix.txt"
	output:
		go_res = "data/interim/{sample}_Affy_GO_term_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} --goterms {input.go_terms} --gofunctions {input.go_functions} > {output.go_res}"


## Performs MP term vs MP term analysis between the Controls vs Cases cohorts
rule affy_MP_term_analysis:
	input:
		script = str(config["scripts"]) + "stat_test_LOF_Affy_MP_term_pval.py",
		gene_list = str(config["chromosome_file_path"]) + "hg19_genes.bed",
		mp_terms = str(config["chromosome_file_path"]) + "human_MP_ws.txt",
		mp_functions = str(config["chromosome_file_path"]) + "mp_def.txt",
		bed = lambda wildcards: config["bed_file"],
		#WES_mat = "data/interim/{sample}_WES_mutation_matrix.txt"
	output:
		mp_res = "data/interim/{sample}_Affy_MP_term_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} --mpterms {input.mp_terms} --mpfunctions {input.mp_functions} > {output.mp_res}"



## Performs MetaP fisher test that conbimes the pvals from the VCF (SNPs) results with the BED (CNVs) file results
rule MetaP_Fisher:
	input:
		script = str(config["scripts"]) + "stat_test_LOF_MetaP_Fisher.py",
		gene2gene = "data/interim/{sample}_gene2gene_res.txt",
		GO = "data/interim/{sample}_GO_term_res.txt",
		MP = "data/interim/{sample}_MP_term_res.txt",
		cnv_gene2gene = "data/interim/{sample}_Affy_gene2gene_res.txt",
		cnv_GO = "data/interim/{sample}_Affy_GO_term_res.txt",
		cnv_MP = "data/interim/{sample}_Affy_MP_term_res.txt"
	output:
		fisher = "data/interim/{sample}_MetaP_Fisher.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} > {output.fisher}"


##############################################################################################################################
######################################## THIS BEGINS THE ANALYSIS OF EACH INDIVIDUAL SAMPLES INDEPENDENTLY ###################
##############################################################################################################################

## Finding significant in GO term of SNPs 
rule individual_metap_SNP_GO:
	input:
		script = str(config["scripts"]) + "Individual_metap_SNP_GO.py",
		go_terms = str(config["chromosome_file_path"]) + "human_GO.txt",
		go_functions = str(config["chromosome_file_path"]) + "go_def.txt",
		WES_mat = "data/interim/{sample}_WES_mutation_matrix.txt"
	output:
		SNP_GO = "data/interim/individual_{sample}_SNP_GO_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} --goterms {input.go_terms} --gofunctions {input.go_functions} > {output.SNP_GO}"


## Finding significant in MP term of SNPs 
rule individual_metap_SNP_MP:
	input:
		script = str(config["scripts"]) + "Individual_metap_SNP_MP.py",
		mp_terms = str(config["chromosome_file_path"]) + "human_MP_ws.txt",
		mp_functions = str(config["chromosome_file_path"]) + "mp_def.txt",
		WES_mat = "data/interim/{sample}_WES_mutation_matrix.txt"
	output:
		SNP_MP = "data/interim/individual_{sample}_SNP_MP_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} --mpterms {input.mp_terms} --mpfunctions {input.mp_functions} > {output.SNP_MP}"


## Finding significant in GO term of CNVs 
rule individual_metap_CNV_GO:
	input:
		script = str(config["scripts"]) + "Individual_metap_CNV_GO.py",
		go_terms = str(config["chromosome_file_path"]) + "human_GO.txt",
		go_functions = str(config["chromosome_file_path"]) + "go_def.txt"
	output:
		CNV_GO = "data/interim/individual_{sample}_CNV_GO_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} --goterms {input.go_terms} --gofunctions {input.go_functions} > {output.CNV_GO}"


## Finding significant in MP term of CNVs 
rule individual_metap_CNV_MP:
	input:
		script = str(config["scripts"]) + "Individual_metap_CNV_MP.py",
		mp_terms = str(config["chromosome_file_path"]) + "human_MP_ws.txt",
		mp_functions = str(config["chromosome_file_path"]) + "mp_def.txt"
	output:
		CNV_MP = "data/interim/individual_{sample}_CNV_MP_res.txt"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} --mpterms {input.mp_terms} --mpfunctions {input.mp_functions} > {output.CNV_MP}"


## With the cohort ANALYSIS and Individual ANALYSIS done. We have enough information to create the REPORT
## So we gather all of the data from the DATABASE and produce the REPORT. 
rule gen_REPORT:
	input:
		fisher = "data/interim/{sample}_MetaP_Fisher.txt",
		SNP_GO = "data/interim/individual_{sample}_SNP_GO_res.txt",
		SNP_MP = "data/interim/individual_{sample}_SNP_MP_res.txt",
		CNV_GO = "data/interim/individual_{sample}_CNV_GO_res.txt",
		CNV_MP = "data/interim/individual_{sample}_CNV_MP_res.txt",
		script = str(config["scripts"]) + "generate_report.py",
		proj_sum = lambda wildcards: config["project_summary"]
	output:
		out = "data/endpoints/{sample}_homepage.html"
	threads: 1
	params:
		mem=r"4G",
		database = lambda wildcards: config["database"]
	shell:
		"python3 {input.script} --database {params.database} --project_summary {input.proj_sum} --homepage_path {output.out}"

